{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf0f540-6b83-4a11-bdb9-5cce5bb86866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import functools\n",
    "import time\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PyQt5.QtCore import Qt, QUrl, QTimer, QCoreApplication\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent\n",
    "from PyQt5.QtMultimediaWidgets import QVideoWidget\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QPushButton, QVBoxLayout, QHBoxLayout, QWidget, QSizePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b246d801-71ed-4ce7-9bfa-eefbd4d2bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_traffic_light():\n",
    "    traffic_light = QLabel()\n",
    "    traffic_light.setFixedSize(100, 200)\n",
    "    traffic_light.setAlignment(Qt.AlignCenter)\n",
    "    return traffic_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d19bf2-37b3-4f63-8e55-28b7048fe962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_traffic_light(traffic_light, state):\n",
    "    if state == 'red':\n",
    "        traffic_light.setStyleSheet(\"background-color: red;\")\n",
    "    elif state == 'green':\n",
    "        traffic_light.setStyleSheet(\"background-color: green;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe2e332-fd41-46c4-8e79-114ba2903f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = tf.keras.models.load_model('rcnn_epoch-02_val_loss-0.10.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325d370d-afeb-445d-ad7a-b583efdc7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    rgb_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "    normalized_image = rgb_image / 255.0\n",
    "    processed_image = np.expand_dims(normalized_image, axis=0)\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695f20e7-d0fe-49af-8348-01e0e3329009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness():\n",
    "    if (datetime.now().day == last_green.day and\n",
    "        datetime.now().month == last_green.month and\n",
    "        datetime.now().year == last_green.year and\n",
    "        (datetime.now() - last_green).total_seconds() < max_minutes * 60):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912f4a30-2f0e-4f91-950c-dadf1fd3ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing():\n",
    "    if fairness():\n",
    "        last_green = datetime.now()\n",
    "        return True\n",
    "    print(\"Not good time\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "284128aa-3ae2-4051-9f40-7734d21a4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_marker(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(gray, 35, 125)\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    return cv2.minAreaRect(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7497b098-4319-45b7-a6e4-8840b119f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_camera(perWidth):\n",
    "    return (KNOWN_DISTANCE * focalLength) / perWidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a4ddc29-9321-4f48-8745-308d1daf94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_similarity(image, box):\n",
    "    x, y, w, h = box\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    mean_color_box = np.mean(roi, axis=(0, 1))\n",
    "    mean_color_object = [120, 100, 50]\n",
    "    distance = np.linalg.norm(mean_color_box - mean_color_object)\n",
    "    similarity = 1 / (1 + distance)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7443be18-e739-4c71-96ab-5912135e3d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waiting_for_me(frame, model):\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    frame_rgb = cv2.cvtColor(frame.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    ss.setBaseImage(frame_rgb)    \n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    ssresults = ss.process()\n",
    "    best_box = None\n",
    "    best_score = 0\n",
    "    for result in ssresults:\n",
    "        x, y, w, h = result\n",
    "        timage = frame_rgb[y:y+h,x:x+w]\n",
    "        resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
    "        img = np.expand_dims(resized, axis=0)\n",
    "        out = model.predict(img)\n",
    "        if out[0][1] < out[0][0]:\n",
    "            score = color_similarity(frame_rgb, result[:4])\n",
    "            combined_score = out[0][0] * score\n",
    "            if combined_score > best_score:\n",
    "                best_box = result\n",
    "                best_score = score\n",
    "    if best_box is not None:\n",
    "        if len(best_box) > 1:\n",
    "            centimeters = distance_to_camera(best_box[3])\n",
    "            print(\"Distance detect: \", centimeters)\n",
    "            if abs(centimeters - KNOWN_DISTANCE) == 30:\n",
    "                if timing():\n",
    "                    return best_box  \n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                print(\"The pedestrian far or close\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11912c17-d08d-46e0-9ffd-edc4ac3d4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pedestrian(frame, model):\n",
    "    res = model.predict(frame)\n",
    "    if res[0][1] < res[0][0]:\n",
    "        return waiting_for_me(frame, model)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d51eb65-fceb-4166-a384-7089dffb1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_frame(media_player, video_path):\n",
    "    current_time = media_player.position()\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, current_time)\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        return frame\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075a2efc-204b-4982-b5da-3f6aebea64dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(media_player, video_url):\n",
    "    media_player.setMedia(QMediaContent(video_url))\n",
    "    media_player.setVolume(0)\n",
    "    media_player.play()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9be7a544-da60-407e-b6d2-6d0c14cfb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(media_player, video_path, traffic_light, model):\n",
    "    frame = capture_frame(media_player, video_path)\n",
    "    if frame is not None:\n",
    "        processed_image = preprocess_image(frame)\n",
    "        pedestrian_detected = detect_pedestrian(processed_image, model)\n",
    "        if pedestrian_detected is not None:\n",
    "            update_traffic_light(traffic_light, 'green')\n",
    "        else:\n",
    "            print(\"No pedestrian detected\")\n",
    "            update_traffic_light(traffic_light, 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ca8a29-f421-46f3-8040-556a2bdb9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_video(media_player, video_path, traffic_light, model, timer):\n",
    "    if media_player.state() == QMediaPlayer.PlayingState:\n",
    "        process_frame(media_player, video_path, traffic_light, model)\n",
    "        QCoreApplication.processEvents()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aabcaaf7-45a0-4a81-8fbd-dc3bdb8535cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_application(window):\n",
    "    window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "067ba57f-d880-4864-b7f2-0b2e037b259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022B6A8D71A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global last_green\n",
    "    global max_minutes\n",
    "    global KNOWN_DISTANCE\n",
    "    global KNOWN_WIDTH\n",
    "    global focalLength\n",
    "\n",
    "    model = load_model()\n",
    "\n",
    "    KNOWN_DISTANCE = 450.0\n",
    "    KNOWN_WIDTH = 40.0\n",
    "    image = cv2.imread(\"img.JPG\")\n",
    "    marker = find_marker(image)\n",
    "    focalLength = (marker[1][0] * KNOWN_DISTANCE) / KNOWN_WIDTH\n",
    "\n",
    "    last_green = datetime(1111, 1, 1, 1, 1, 1)\n",
    "    max_minutes = 1\n",
    "\n",
    "    app = QApplication(sys.argv)\n",
    "    video_path = r\"video_1.mp4\"\n",
    "    video_url = QUrl.fromLocalFile(video_path)\n",
    "\n",
    "    window = QWidget()\n",
    "    window.setWindowTitle(\"PyQt5 Video Player with Traffic Light\")\n",
    "    window.setGeometry(100, 100, 1200, 800)\n",
    "\n",
    "    video_widget = QVideoWidget()\n",
    "    video_widget.setMinimumSize(600, 400)\n",
    "    video_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n",
    "\n",
    "    media_player = QMediaPlayer(None, QMediaPlayer.VideoSurface)\n",
    "    media_player.setVideoOutput(video_widget)\n",
    "\n",
    "    traffic_light = QLabel()\n",
    "    traffic_light.setFixedSize(100, 200)\n",
    "    traffic_light.setAlignment(Qt.AlignCenter)\n",
    "    update_traffic_light(traffic_light, 'red')\n",
    "\n",
    "\n",
    "    exit_button = QPushButton(\"Exit\")\n",
    "    exit_button.clicked.connect(functools.partial(exit_application, window))\n",
    "\n",
    "    layout = QHBoxLayout()\n",
    "    layout.addWidget(video_widget)\n",
    "    layout.addWidget(traffic_light)\n",
    "\n",
    "    button_layout = QHBoxLayout()\n",
    "    button_layout.addWidget(exit_button)\n",
    "\n",
    "    main_layout = QVBoxLayout()\n",
    "    main_layout.addLayout(layout)\n",
    "    main_layout.addLayout(button_layout)\n",
    "\n",
    "    window.setLayout(main_layout)\n",
    "\n",
    "    timer = QTimer()\n",
    "    timer.setInterval(5000)  \n",
    "    timer.timeout.connect(lambda: process_frame(media_player, video_path, traffic_light, model))\n",
    "\n",
    "    window.show()\n",
    "    \n",
    "    play_video(media_player, video_url)  \n",
    "    timer.start() \n",
    "\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
